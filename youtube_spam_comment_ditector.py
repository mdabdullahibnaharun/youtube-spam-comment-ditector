# -*- coding: utf-8 -*-
"""youtube_spam_comment_ditector.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ECmipMYkUcsCSIuvuhymFvaak5-cUD2j

Md. Abdullah Ibna Harun	193-15-13426	abdullah15-13426@diu.edu.bd

Mahade Hasan Forhad	193-15-13355	mahade15-13355@diu.edu.bd

https://github.com/mdabdullahibnaharun/youtube-spam-comment-ditector

## Import modules dataset
"""

#-------------- Youtube Spam Comment Detector--------------------#

# converting words into vectors to use as fetures to help in classification

#EDA packages
import pandas as pd
import numpy as np

# Ml packages for vectorization of text for feature extraction

from sklearn.feature_extraction.text import CountVectorizer
from sklearn.feature_extraction.text import TfidfVectorizer

# Visualization packages

import matplotlib.pyplot as plt
import seaborn as sns

from google.colab import files

uploaded = files.upload()

for fn in uploaded.keys():
  print('User uploaded file "{name}" with length {length} bytes'.format(
      name=fn, length=len(uploaded[fn])))

#Dataset from Kaggle
df1 = pd.read_csv("Youtube01-Psy.csv")
df1.head()

#load all dataset to mearge them
df2 = pd.read_csv("Youtube02-KatyPerry.csv")
df3 = pd.read_csv("Youtube03-LMFAO.csv")
df4= pd.read_csv("Youtube04-Eminem.csv")
df5= pd.read_csv("Youtube05-Shakira.csv")

"""## Data Visualization"""

data = df1['CLASS'].value_counts()
name= data.index
count = data.values 

plt.title("Psy")
plt.xlabel('Comment-Ratio')
plt.ylabel('Total count')

plt.bar(name,count)

data = df2['CLASS'].value_counts()
name= data.index
count = data.values 

plt.title("KatyPerry")
plt.xlabel('Comment-Ratio')
plt.ylabel('Total count')

plt.bar(name,count)

data = df3['CLASS'].value_counts()
name= data.index
count = data.values 

plt.title("LMFAO")
plt.xlabel('Comment-Ratio')
plt.ylabel('Total count')


plt.bar(name,count)

data = df4['CLASS'].value_counts()
name= data.index
count = data.values 

plt.title("Eminem")
plt.xlabel('Comment-Ratio')
plt.ylabel('Total count')

plt.bar(name,count)

data = df5['CLASS'].value_counts()
name= data.index
count = data.values 

plt.title("Shakira")
plt.xlabel('Comment-Ratio')
plt.ylabel('Total count')

plt.bar(name,count)

value1=df5['CLASS'].value_counts()
value2=df5['CLASS'].value_counts()
value3=df5['CLASS'].value_counts()
value4=df5['CLASS'].value_counts()
value5=df5['CLASS'].value_counts()
box_plot_data = [value1, value2, value3, value4, value5]

plt.boxplot(box_plot_data,patch_artist=True,labels = ['Psy' , 'KatyPerry','LMFAO','Eminem','Shakira'])
plt.show()

"""## Preprocessing"""

frames = [df1,df2,df3,df4,df5]

df_mearged = pd.concat(frames)

df_mearged

# total size
df_mearged.shape

# mearging with keys
keys = ["Psy","KatyPerry","LMFAO","Eminem","Shakira"]
df_with_keys = pd.concat(frames,keys = keys)
df_with_keys

# checking for only comments on psy
df_with_keys.loc["Psy"]

# save and write mearge data to a csv file
df_with_keys.to_csv("YoutubeSpamMergedData01.csv")

"""## Data Visualization after Preprocessing"""

# getting data from mearge dataset.

df= pd.read_csv("YoutubeSpamMergedData01.csv")
df

#data size
df.size

slices = df['CLASS'].value_counts()
activity = ['Posetive' , 'Negative']
cols = ['g','r']

plt.pie(slices,
        labels = activity,
        colors = cols,
        startangle = 0,
        shadow = False,
        explode = (0,0),
        autopct = "%1.2f%%",
        radius = 1)

plt.title('spam comments ratio')
plt.show()

"""## Data cleaning"""

# checking for consistent column name
df.columns

# checking data types
df.dtypes

# checking for missing nan
df.isnull().sum()

# check for date
df['DATE']

# getting author details 
df.AUTHOR
# if i convert the auther name to first and last bname then
#df[["FIRSTNAME"],["LASTNAME"]] = df['AUTHOR'].str.split(expand=True)

## working with text content
df_data = df[['CONTENT','CLASS']]
# to see those values content =  comments && class = true/false
df_data

# to see new dataset coluimns
df_data.columns

# inserting data inn x,y for visualization
df_x = df_data['CONTENT']
df_y = df_data['CLASS']

"""## Feature Selection"""

### Feature Extraction From Text

#1 CountVectorizer
#2 TfidfVectorizer

cv = CountVectorizer()

ex = cv.fit_transform(["Great song but check this out","What is this song"])

# convertion to arry
ex.toarray()

# gettingh feature name
cv.get_feature_names()

"""## Feature Extraction and Feature Engineering"""

# extrat feature with CountVectorizer
corpus = df_x
cv = CountVectorizer()
X = cv.fit_transform(corpus)

# convertingf x to an aray
X.toarray()

# get the feature names
cv.get_feature_names()

"""## Model Building"""

# module building
from sklearn.model_selection import train_test_split

#training
X_train,X_test,y_train,y_test = train_test_split(X,df_y,test_size=0.33,random_state = 42)

# see X_train
X_train

"""## Analyzer and apply algorithm"""

from sklearn.neighbors import KNeighborsClassifier,KNeighborsRegressor
KNNC = KNeighborsClassifier()
KNNC.fit(X_train,y_train)
print(f"Train Accuracy of model {KNNC.score(X_train,y_train)*100} %")
# acuracy of our model
print(f"Test Accuracy of model {KNNC.score(X_test,y_test)*100} %")

from sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor
dtc = DecisionTreeClassifier()
dtc.fit(X_train,y_train)
print(f"Train Accuracy of model {dtc.score(X_train,y_train)*100} %")
# acuracy of our model
print(f"Test Accuracy of model {dtc.score(X_test,y_test)*100} %")

from sklearn.ensemble import RandomForestClassifier, RandomForestRegressor
Rfc= RandomForestClassifier()
Rfc.fit(X_train,y_train)
print(f"Train Accuracy of model {Rfc.score(X_train,y_train)*100} %")
# acuracy of our model
print(f"Test Accuracy of model {Rfc.score(X_test,y_test)*100} %")

from sklearn.svm import SVC
from pandas.core.common import random_state
svc = SVC(random_state=101)
svc.fit(X_train,y_train)
print(f"Train Accuracy of model {svc.score(X_train,y_train)*100} %")
# acuracy of our model
print(f"Test Accuracy of model {svc.score(X_test,y_test)*100} %")

# Naive Bayes Classifire
from sklearn.naive_bayes import MultinomialNB
clf = MultinomialNB()
clf.fit(X_train,y_train)
print(f"Train Accuracy of model {clf.score(X_train,y_train)*100} %")
# acuracy of our model
print(f"Test Accuracy of model {clf.score(X_test,y_test)*100} %")

"""## Confusion Matrix"""

from sklearn.metrics import plot_confusion_matrix
import matplotlib.pyplot as plt
plot_confusion_matrix(clf,X_test,y_test,cmap='BuPu_r',display_labels=['negative','positive'])
plt.show()

"""## Predict & Output"""

## predict with our model
clf.predict(X_test)

"""## Testing"""

## TEST 1

# a simple prediction 1
comment = ["Check this out"]
vect = cv.transform(comment).toarray()
vect

clf.predict(vect)

class_dict = {"Not Spam":0,"Spam":1}
class_dict.values()

if clf.predict(vect) == 1:
    print("Spam")
else:
    print("Not Spam")

## TEST 2

# simple Prerdiction 2
comment1 = [str(input())]
vect = cv.transform(comment1).toarray()
print(clf.predict(vect))
if clf.predict(vect) == 1:
    print("Spam")
else:
    print("Not Spam")

"""## Save The model"""

import pickle as pk

naivebayesML = open("YtbSpam_model.pkl","wb")

pk.dump(clf,naivebayesML)

naivebayesML.close()

## load the model

ytb_model = open("YtbSpam_model.pkl","rb")

new_model = pk.load(ytb_model)

new_model



